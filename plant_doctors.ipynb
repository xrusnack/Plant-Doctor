{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYqStE6Cl-gO"
      },
      "source": [
        "## **Plant Doctor**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jckDKTZJmadK",
        "outputId": "6d9842f6-9dff-4fbf-d42f-4bc84ef71a8c"
      },
      "outputs": [],
      "source": [
        "!mkdir plantdisease\n",
        "\n",
        "!curl -L -o plantdisease.zip\\\n",
        "  https://www.kaggle.com/api/v1/datasets/download/emmarex/plantdisease\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8WO-pQc3IuGe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip plantdisease.zip -d plantdisease/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_global_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_global_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "NVm-0GjXl-gP",
        "outputId": "e76147a2-d303-4c6a-ce7c-68cb6b9db9a1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(\"plantdisease/PlantVillage\")\n",
        "\n",
        "labels = os.listdir(path)\n",
        "counts = [len(os.listdir(os.path.join(path, label))) for label in labels]\n",
        "\n",
        "plt.figure(figsize=(11, 5))\n",
        "plt.bar(labels, counts, color='skyblue')\n",
        "plt.ylabel(\"Image count\")\n",
        "plt.ylabel(\"Label\")\n",
        "\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69WMfTHll-gQ"
      },
      "source": [
        "### Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiRrl-3Dl-gQ",
        "outputId": "b8dd25b2-8dc4-4743-ffa4-22584d61a600",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(path):\n",
        "    data = []\n",
        "\n",
        "    for p in path.iterdir():\n",
        "        for image in p.iterdir():\n",
        "            if image.suffix.lower() == \".jpg\":\n",
        "                data.append((image, image.parents[0].stem))\n",
        "\n",
        "    return pd.DataFrame(data, columns=['path', 'label'])\n",
        "\n",
        "df = load_data(path)\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.1)\n",
        "\n",
        "print(train_df.shape)\n",
        "print(valid_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-hYjAH3l-gR",
        "outputId": "0bdcd808-0d65-449c-cffd-44b6bb981326",
        "tags": []
      },
      "outputs": [],
      "source": [
        "label_map = {label: i for i, label in enumerate(os.listdir(path))}\n",
        "print(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jYrbIWC_l-gR",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "\n",
        "\n",
        "class Data(data.Dataset):\n",
        "    def __init__(self, df, label_map, transforms=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.df = df\n",
        "\n",
        "        self.label_map = label_map\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.df.iloc[index]\n",
        "        img = pil_to_tensor(Image.open(sample.path)) / 255\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = img.permute(1, 2, 0).numpy()\n",
        "            img = self.transforms(image=img)['image']\n",
        "\n",
        "        return img, self.label_map[sample.label]\n",
        "\n",
        "\n",
        "train = Data(train_df, label_map)\n",
        "valid = Data(valid_df, label_map)\n",
        "test = Data(test_df, label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q7Wfwpnl-gR"
      },
      "source": [
        "### Data Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu33ucpJl-gS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_dataset_stats(ds):\n",
        "    images = torch.stack([im[0] for im in ds])\n",
        "\n",
        "    ds_mean = images.mean(dim=(0, 2, 3))\n",
        "    ds_std = images.std(dim=(0, 2, 3))\n",
        "\n",
        "    return ds_mean.tolist(), ds_std.tolist()\n",
        "\n",
        "\n",
        "mean, std = get_dataset_stats(train)\n",
        "print(f'Dataset stats\\n  mean:\\t {mean}\\n  std:\\t {std}' )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "piuB8-pDl-gS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def ishow(img,\n",
        "          cmap='viridis',\n",
        "          title='',\n",
        "          fig_size=(8,6),\n",
        "          colorbar=False,\n",
        "          interpolation='none'):\n",
        "    ' Function `ishow` displays an image in a new window. '\n",
        "\n",
        "    #extent = (0, img.shape[1], img.shape[0], 0)\n",
        "    fig, ax = plt.subplots(figsize=fig_size)\n",
        "    pcm = ax.imshow(img,\n",
        "              #extent=extent,\n",
        "              cmap=cmap,\n",
        "              interpolation=interpolation)\n",
        "\n",
        "    ax.set_frame_on(False)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    if colorbar:\n",
        "        fig.colorbar(pcm, orientation='vertical')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Li941Crl-gS"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bhleegf3l-gT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show_augmentations(ds, idx, n_samples=3):\n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "\n",
        "    cols, rows = n_samples, n_samples\n",
        "    sample_img, label = ds[idx]\n",
        "\n",
        "    for i in range(1, cols * rows + 1):\n",
        "        img, _ = ds[idx]\n",
        "\n",
        "        img_np = img.permute(1, 2, 0).cpu().detach().numpy()\n",
        "\n",
        "        if img_np.min() < 0 or img_np.max() > 1:\n",
        "\n",
        "            print(f'The image values were shifted to the range (0, 1). The original range is ({img.min():.04f}), {img.max():.04f})')\n",
        "            img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
        "            print(img_np.min(), img_np.max())\n",
        "        figure.add_subplot(rows, cols, i)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(img_np)\n",
        "\n",
        "    plt.suptitle(f'sample no {idx}, label {label}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x8HRuFg1l-gT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224,224), # for vgg\n",
        "    A.HorizontalFlip(p=.5),\n",
        "    A.VerticalFlip(p=.5),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    #A.GaussianBlur(blur_limit=3, p=0.1),\n",
        "    #A.GaussNoise(p=0.1),\n",
        "    #A.CenterCrop(width=56, height=56),\n",
        "    #A.ElasticTransform(p=0.3),\n",
        "    A.CLAHE(clip_limit=2, p=0.1),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.1),\n",
        "    A.Normalize(\n",
        "        mean=mean,\n",
        "        std=std,\n",
        "        normalization=\"image_per_channel\"\n",
        "    ),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "valid_transform = A.Compose([\n",
        "    A.Resize(224,224),\n",
        "    A.Normalize(\n",
        "        mean=mean,\n",
        "        std=std,\n",
        "        normalization=\"image_per_channel\"\n",
        "    ),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "train = Data(train_df, label_map, train_transform)\n",
        "valid = Data(valid_df, label_map, valid_transform)\n",
        "test = Data(test_df, label_map, valid_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5imscZIl-gT",
        "outputId": "68d70b28-3d94-4e52-c4a9-899c89044f97",
        "tags": []
      },
      "outputs": [],
      "source": [
        "show_augmentations(train, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I2X5fBM0l-gU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# rebalance the classes\n",
        "class_counts = train_df['label'].value_counts().rename(\"count\")\n",
        "class_weights = (1.0 / class_counts).rename(\"weight\")\n",
        "class_weights /= class_weights.sum()\n",
        "sample_weights = train_df['label'].map(class_weights).astype(np.float32).values\n",
        "\n",
        "sampler = WeightedRandomSampler(weights=sample_weights.tolist(), num_samples=len(sample_weights), replacement=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iClhbDKll-gU",
        "outputId": "d9b4650e-0e24-4368-c418-c22ea19cb010",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(pd.concat([class_counts, class_weights], axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK4Y1Sxnl-gU"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sg9nwPJvl-gU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dataloader, device):\n",
        "        self.dataloader = dataloader\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataloader)\n",
        "\n",
        "    def __iter__(self):  # send only one batch to the device every iteration\n",
        "        batches = iter(self.dataloader)\n",
        "        for x, y in batches:\n",
        "            yield x.to(self.device), y.to(self.device)\n",
        "\n",
        "bs = 64\n",
        "\n",
        "train_dataloader = WrappedDataLoader(DataLoader(train, batch_size=bs, sampler=sampler), device)\n",
        "val_dataloader = WrappedDataLoader(DataLoader(valid, batch_size=bs, shuffle=True), device)\n",
        "test_dataloader = WrappedDataLoader(DataLoader(test, batch_size=bs), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Guhn9f39l-gU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import math\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "def update(model, loss_f, inputs, targets, optimizer=None):\n",
        "\n",
        "    # with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    loss = loss_f(outputs, targets)\n",
        "\n",
        "    if optimizer is not None:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss.item(), len(inputs), torch.sum(preds == targets.data)\n",
        "\n",
        "\n",
        "def train(epochs, model, loss_f, optimizer, scheduler, train_dl, valid_dl):\n",
        "    val_loss = []\n",
        "    train_loss = []\n",
        "    best_acc = -math.inf\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        losses, inputs_size, _ = zip(*[update(model, loss_f, inputs, targets, optimizer)\n",
        "                                           for inputs, targets in tqdm(train_dl)])\n",
        "\n",
        "        epoch_train_loss = np.sum(np.multiply(losses, inputs_size)) / np.sum(inputs_size)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            losses, inputs_size, corrects = zip(*[update(model, loss_f, inputs, targets)\n",
        "                                                  for inputs, targets in valid_dl])\n",
        "\n",
        "        epoch_val_loss = np.sum(np.multiply(losses, inputs_size)) / np.sum(inputs_size)\n",
        "        val_loss.append(epoch_val_loss)\n",
        "\n",
        "        epoch_val_acc = np.sum([c.cpu().numpy() for c in corrects]) / np.sum(inputs_size)\n",
        "\n",
        "        if epoch_val_acc > best_acc:\n",
        "            best_acc = epoch_val_acc\n",
        "            state_dict = deepcopy(model.state_dict())\n",
        "            print(f'New best Acc: {best_acc:4f}')\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {epoch_train_loss:.5f}, Validation Loss: {epoch_val_loss:.5f}\")\n",
        "\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHR1lFBbl-gU",
        "outputId": "21e8208c-3c57-476a-86ea-d9f2fa4fb91c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "vgg19 = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).to(device)\n",
        "\n",
        "summary(vgg19, input_size=(3, 224, 224), device=device.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtD-eLs3l-gU",
        "outputId": "8457a02d-3b54-4a8c-f271-91cb4de3dc9b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for param in vgg19.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_in_features = vgg19.classifier[6].in_features\n",
        "vgg19.classifier[6] = nn.Linear(in_features=num_in_features, out_features=len(label_map)).to(device)\n",
        "\n",
        "summary(vgg19, input_size=(3, 224, 224), device=device.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision(\"high\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS0MtmAsl-gV",
        "outputId": "8c316bf1-5d73-4fb0-8d42-453b336cc539",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch.optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn as nn\n",
        "\n",
        "#vgg19 = torch.compile(vgg19)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(vgg19.parameters(), lr=1e-3, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "_, _ = train(epochs=10, model=vgg19, loss_f=loss_func, optimizer=optimizer,\n",
        "             scheduler=scheduler,train_dl=train_dataloader, valid_dl=val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYFi2IAyl-gV",
        "outputId": "b278e249-2ad5-4152-9516-2b845067a850",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for param in vgg19.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(vgg19.parameters(), lr=1e-6, weight_decay=1e-4, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "\n",
        "train_loss, val_loss = train(epochs=15, model=vgg19, loss_f=loss_func, optimizer=optimizer, scheduler=scheduler,\n",
        "                             train_dl=train_dataloader, valid_dl=val_dataloader)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss, linestyle='--')\n",
        "plt.legend(['training loss',\n",
        "           'validation loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD7DV5i9l-gV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.save(vgg19.state_dict(), 'vgg19_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fHH6PVql-gV"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY5kRVytl-gV",
        "outputId": "49d7d0bd-1689-4e0b-b0a9-43ee806665d7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_dl):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, targets in tqdm(test_dl):\n",
        "            batch, targets = batch.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(batch)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(targets.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "y_true, y_pred = evaluate(vgg19, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8frgKCml-gV",
        "outputId": "ee6c4c11-2400-4c26-f736-2f6edfa3c305",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, class_names):\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "\n",
        "print_confusion_matrix(y_true, y_pred, list(label_map.keys()))\n",
        "\n",
        "accuracy = (np.array(y_true) == np.array(y_pred)).sum() / len(y_true)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krl4vXnll-gV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
